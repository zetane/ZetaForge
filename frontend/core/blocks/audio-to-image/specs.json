{
  "information": {
    "id": "audio-to-image",
    "name": "Audio To Image",
    "description": "Transcribing audio into text using OpenAI's speech-to-text model, followed by generating an image based on the transcribed text using OpenAI's text-to-image capabilities. This process converts spoken content into both written and visual forms.",
    "system_versions": [
      "0.1"
    ],
    "block_version": "block version number",
    "block_source": "core/blocks/audio-to-image",
    "block_type": "compute"
  },
  "inputs": {
    "audio_path": {
      "type": "Any",
      "connections": [],
      "relays": []
    },
    "openai_api_key": {
      "type": "Any",
      "connections": [],
      "relays": []
    }
  },
  "outputs": {
    "result": {
      "type": "Any",
      "connections": [],
      "relays": []
    }
  },
  "action": {
    "container": {
      "image": "audio-to-image",
      "version": "latest",
      "command_line": [
        "python",
        "-u",
        "entrypoint.py"
      ]
    }
  },
  "views": {
    "node": {
      "behavior": "modal",
      "active": "True",
      "title_bar": {
        "background_color": "#6b2be0"
      },
      "preview": {},
      "html": "",
      "pos_x": "1053",
      "pos_y": "489",
      "pos_z": "999"
    }
  },
  "events": {}
}