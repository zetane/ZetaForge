{
  "information": {
    "id": "audio-to-image",
    "name": "Audio To Image",
    "description": "Transcribing audio into text using OpenAI's speech-to-text model, followed by generating an image based on the transcribed text using OpenAI's text-to-image capabilities. This process converts spoken content into both written and visual forms.",
    "system_versions": [
      "0.1"
    ],
    "block_version": "block version number",
    "block_source": "core/blocks/audio-to-image",
    "block_type": "compute"
  },
  "inputs": {
    "audio_path": {
      "type": "str",
      "connections": [
        {
          "block": "parameter-ujsaceiv9l8j",
          "variable": "parameter"
        }
      ]
    },
    "openai_api_key": {
      "type": "str",
      "connections": [
        {
          "block": "parameter-rvughst28ayf",
          "variable": "parameter"
        }
      ]
    }
  },
  "outputs": {
    "result": {
      "type": "List[file]",
      "connections": [
        {
          "block": "view-images-c4ftry5wcdff",
          "variable": "image_paths_view"
        }
      ]
    }
  },
  "action": {
    "container": {
      "image": "audio-to-image",
      "version": "audio-to-image-4oippnh3g1pu",
      "command_line": [
        "python",
        "-u",
        "entrypoint.py"
      ]
    },
    "resources": {
      "cpu": {
        "request": "",
        "limit": ""
      },
      "memory": {
        "request": "",
        "limit": ""
      },
      "gpu": {
        "count": 0
      }
    }
  },
  "views": {
    "node": {
      "active": "True or False",
      "title_bar": {
        "background_color": "#6b2be0"
      },
      "preview": {},
      "html": "",
      "pos_x": "1319",
      "pos_y": "604",
      "pos_z": "999",
      "behavior": "modal",
      "order": {
        "input": [
          "audio_path",
          "openai_api_key"
        ],
        "output": [
          "result"
        ]
      }
    }
  },
  "events": {}
}